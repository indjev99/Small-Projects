{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "import _pickle as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = cp.load(open('winequality-white.pickle','rb'))\n",
    "\n",
    "N, D = X.shape\n",
    "N_train = int(0.8 * N)\n",
    "N_test = N - N_train\n",
    "\n",
    "X_train_raw = X[:N_train]\n",
    "y_train = y[:N_train]\n",
    "X_test_raw = X[N_train:]\n",
    "y_test = y[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "\n",
    "def get_norms(X):\n",
    "    means = np.mean(X, axis=0)\n",
    "    stds = np.std(X, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def normalize(X, means, stds):\n",
    "    return (X - means) / stds\n",
    "\n",
    "X_means, X_stds = get_norms(X_train_raw)\n",
    "X_train = normalize(X_train_raw, X_means, X_stds)\n",
    "X_test = normalize(X_test_raw, X_means, X_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a mode\n",
    "\n",
    "def mean_squared_error(predict, X, y):\n",
    "    y_hat = predict(X)\n",
    "    residuals = np.subtract(y, y_hat)\n",
    "    squared_residuals = np.square(residuals)\n",
    "    return np.mean(squared_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of model\n",
    "\n",
    "def print_summary(name, train, predict):\n",
    "    train(X_train, y_train)\n",
    "    mse_train = mean_squared_error(predict, X_train, y_train)\n",
    "    mse_test = mean_squared_error(predict, X_test, y_test)\n",
    "\n",
    "    print('Mean squared error of ' + name + ':')\n",
    "    print('On train data ' + str(mse_train))\n",
    "    print('On test data ' + str(mse_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot leaning curve of model\n",
    "\n",
    "def plot_learning_curve(train, predict, fr, to):\n",
    "    mse_train_arr = np.zeros(0)\n",
    "    mse_test_arr = np.zeros(0)\n",
    "    n_arr = np.zeros(0)\n",
    "\n",
    "    for i in range(20 * fr, 20 * to + 1, 20):\n",
    "        X_curr = X_train[:i]\n",
    "        y_curr = y_train[:i]\n",
    "\n",
    "        train(X_curr, y_curr)\n",
    "        mse_train = mean_squared_error(predict, X_curr, y_curr)\n",
    "        mse_test = mean_squared_error(predict, X_test, y_test)\n",
    "\n",
    "        n_arr = np.append(n_arr, i)\n",
    "        mse_train_arr = np.append(mse_train_arr, mse_train)\n",
    "        mse_test_arr = np.append(mse_test_arr, mse_test)\n",
    "\n",
    "    plt.plot(n_arr, mse_train_arr)\n",
    "    plt.plot(n_arr, mse_test_arr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trivial model\n",
    "\n",
    "def train_trivial(X, y):\n",
    "    global avg_y\n",
    "    avg_y = np.average(y)\n",
    "\n",
    "def predict_trivial(X):\n",
    "    return np.repeat(avg_y, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def transform_const(X):\n",
    "    return np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "def train_lin_reg(X, y):\n",
    "    global weights\n",
    "    X2 = transform_const(X)\n",
    "    weights = inv(X2.transpose().dot(X2)).dot(X2.transpose()).dot(y)\n",
    "\n",
    "def predict_lin_reg(X):\n",
    "    return transform_const(X).dot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial basis expansion\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def transform_poly_raw(X):\n",
    "    poly = PolynomialFeatures(2)\n",
    "    return poly.fit_transform(X)\n",
    "\n",
    "def transform_poly(X):\n",
    "    return normalize(transform_poly_raw(X), X_poly_means, X_poly_stds)\n",
    "\n",
    "def get_poly_norms():\n",
    "    global X_poly_means, X_poly_stds\n",
    "    X_poly_train_raw = transform_poly_raw(X_train)\n",
    "    X_poly_means, X_poly_stds = get_norms(X_poly_train_raw)\n",
    "    X_poly_means[0] = 0\n",
    "    X_poly_stds[0] = 1\n",
    "\n",
    "get_poly_norms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with polynomial\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def train_lin_reg_poly(X, y):\n",
    "    global weights\n",
    "    X2 = transform_poly(X)\n",
    "    weights = inv(X2.transpose().dot(X2)).dot(X2.transpose()).dot(y)\n",
    "\n",
    "def predict_lin_reg_poly(X):\n",
    "    return transform_poly(X).dot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge linear regression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def train_ridge(alpha, X, y):\n",
    "    global clf_ridge\n",
    "    clf_ridge = Ridge(alpha)\n",
    "    clf_ridge.fit(transform_poly(X), y)\n",
    "\n",
    "def predict_ridge(X):\n",
    "    return clf_ridge.predict(transform_poly(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso linear regression\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def train_lasso(alpha, X, y):\n",
    "    global clf_lasso\n",
    "    clf_lasso = Lasso(alpha)\n",
    "    clf_lasso.fit(transform_poly(X), y)\n",
    "\n",
    "def predict_lasso(X):\n",
    "    return clf_lasso.predict(transform_poly(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit alpha hyperparameter for a model\n",
    "\n",
    "N_vtrain = int(0.8 * N_train)\n",
    "X_vtrain = X_train[:N_vtrain]\n",
    "y_vtrain = y_train[:N_vtrain]\n",
    "X_valid = X_train[N_vtrain:]\n",
    "y_valid = y_train[N_vtrain:]\n",
    "    \n",
    "def find_alpha(train, predict):\n",
    "    def check_alpha(alpha):\n",
    "        train(alpha, X_vtrain, y_vtrain)\n",
    "        mse = mean_squared_error(predict, X_valid, y_valid)\n",
    "        return mse\n",
    "    \n",
    "    alphas = [0.01, 0.1, 1, 10, 100]\n",
    "    res = map(check_alpha, alphas)\n",
    "    return alphas[np.argmin(list(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal alpha hyperparameters for the two models\n",
    "\n",
    "ridge_alpha = find_alpha(train_ridge, predict_ridge)\n",
    "lasso_alpha = find_alpha(train_lasso, predict_lasso)\n",
    "\n",
    "print('Ridge alpha: ' + str(ridge_alpha))\n",
    "print('Lasso alpha: ' + str(lasso_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of ys\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.bar(unique, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "\n",
    "def apply_hyper(train, alpha):\n",
    "    return (lambda X, y: train(alpha, X, y))\n",
    "\n",
    "print_summary('trivial model', train_trivial, predict_trivial)\n",
    "print_summary('linear regression', train_lin_reg, predict_lin_reg)\n",
    "print_summary('ridge regression', apply_hyper(train_ridge, ridge_alpha), predict_ridge)\n",
    "print_summary('lasso regression', apply_hyper(train_lasso, lasso_alpha), predict_lasso)\n",
    "print_summary('linear regression w/ polynomial', train_lin_reg_poly, predict_lin_reg_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "\n",
    "plot_learning_curve(train_lin_reg, predict_lin_reg, 1 , 30)\n",
    "plot_learning_curve(apply_hyper(train_ridge, ridge_alpha), predict_ridge, 10, 100)\n",
    "plot_learning_curve(apply_hyper(train_lasso, lasso_alpha), predict_lasso, 10, 100)\n",
    "plot_learning_curve(train_lin_reg_poly, predict_lin_reg_poly, 10, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
